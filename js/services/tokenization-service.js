/**
 * Servicio de Tokenizaci√≥n
 * Maneja toda la l√≥gica de tokenizaci√≥n incluyendo integraci√≥n tiktoken y m√©todos de respaldo
 */

class TokenizationService {
    constructor() {
        this.encoder = null;
        this.isInitialized = false;
        this.initPromise = this.initializeTokenizer();
    }

    /**
     * Inicializa el tokenizador tiktoken
     * @returns {Promise<void>}
     */
    async initializeTokenizer() {
        try {
            console.log('Esperando carga de tiktoken...');
            
            // Esperar hasta que tiktoken est√© disponible (real o respaldo)
            let attempts = 0;
            const maxAttempts = 20; // 10 segundos m√°ximo
            
            while (attempts < maxAttempts) {
                if (typeof window !== 'undefined' && window.tiktokenLoaded) {
                    break;
                }
                await new Promise(resolve => setTimeout(resolve, 500));
                attempts++;
            }
            
            console.log('Verificando disponibilidad de tiktoken...');
            
            // Intentar diferentes formas de acceder a tiktoken
            let tiktokenLib = null;
            
            // Verificar en contexto global
            if (typeof tiktoken !== 'undefined') {
                tiktokenLib = tiktoken;
                console.log('tiktoken encontrado en contexto global');
            }
            // Verificar en window
            else if (typeof window !== 'undefined' && window.tiktoken) {
                tiktokenLib = window.tiktoken;
                console.log('tiktoken encontrado en window');
            }
            
            if (tiktokenLib && typeof tiktokenLib.get_encoding === 'function') {
                try {
                    console.log('Inicializando encoder cl100k_base...');
                    this.encoder = tiktokenLib.get_encoding('cl100k_base');
                    this.isInitialized = true;
                    
                    // Determinar si es tiktoken real o respaldo
                    const isRealTiktoken = !window.tiktokenFallback;
                    console.log(isRealTiktoken ? 'Tiktoken REAL inicializado correctamente' : 'üîß Tiktoken RESPALDO inicializado correctamente');
                    
                    // Hacer una prueba r√°pida
                    const testTokens = this.encoder.encode('Hola mundo');
                    console.log('Prueba de tokenizaci√≥n:', {
                        texto: 'Hola mundo',
                        tokens: testTokens,
                        tipo: isRealTiktoken ? 'IDs REALES' : 'IDs APROXIMADOS'
                    });
                    
                    // Guardar el tipo para referencia
                    this.isRealTiktoken = isRealTiktoken;
                    
                } catch (error) {
                    console.error('Error al inicializar encoder tiktoken:', error);
                    this.isInitialized = false;
                }
            } else {
                console.error('tiktoken no est√° disponible despu√©s de esperar');
                this.isInitialized = false;
            }
        } catch (error) {
            console.error('Error durante la inicializaci√≥n del tokenizador:', error);
            this.isInitialized = false;
        }
    }

    /**
     * Espera a que el tokenizador sea inicializado
     * @returns {Promise<void>}
     */
    async waitForInitialization() {
        await this.initPromise;
    }

    /**
     * Tokeniza texto usando el m√©todo apropiado
     * @param {string} text - Texto a tokenizar
     * @param {string} modelId - Identificador del modelo
     * @returns {Promise<{tokens: Array, count: number}>}
     */
    async tokenizeText(text, modelId) {
        if (!text.trim()) {
            return { tokens: [], count: 0 };
        }

        await this.waitForInitialization();

        const modelInfo = MODELS_DATA[modelId];
        let tokenCount = 0;
        let tokens = [];

        // Intentar usar tiktoken para obtener IDs reales y precisos
        if (this.isInitialized && this.encoder && modelInfo.encoding === MODEL_ENCODINGS.CL100K_BASE) {
            try {
                console.log('Tokenizando con tiktoken para obtener IDs precisos...');
                
                // Codificar el texto para obtener los IDs num√©ricos reales
                const encoded = this.encoder.encode(text);
                tokenCount = encoded.length;
                
                console.log(`Texto: "${text}" ‚Üí ${tokenCount} tokens`);
                console.log('IDs codificados:', encoded);
                
                // Aplicar ratio espec√≠fico del modelo para modelos no-OpenAI
                if (modelInfo.tokenRatio) {
                    tokenCount = Math.round(tokenCount * modelInfo.tokenRatio);
                }

                // Crear objetos de token con IDs reales de tiktoken
                tokens = this.createTokensFromEncoding(text, encoded, modelId);
                
                // Verificar que tenemos los IDs correctos
                const idsVerification = tokens.map(t => t.tokenId);
                console.log('Verificaci√≥n de IDs capturados:', idsVerification);
                
            } catch (error) {
                console.error('Error de tokenizaci√≥n tiktoken:', error);
                return this.fallbackTokenization(text, modelId);
            }
        } else {
            console.log('Usando tokenizaci√≥n de respaldo (tiktoken no disponible)');
            // Tokenizaci√≥n de respaldo para otras codificaciones o cuando tiktoken falla
            return this.fallbackTokenization(text, modelId);
        }

        return {
            tokens: tokens,
            count: tokenCount
        };
    }

    /**
     * Crea tokens visuales desde la codificaci√≥n tiktoken
     * @param {string} text - Texto original
     * @param {Array} encoded - Array de tokens codificados
     * @param {string} modelId - Identificador del modelo
     * @returns {Array} Objetos de token para visualizaci√≥n
     */
    createTokensFromEncoding(text, encoded, modelId) {
        try {
            // Verificar que tenemos el encoder y los datos codificados
            if (!this.encoder || !encoded || encoded.length === 0) {
                console.warn('Encoder no disponible o datos vac√≠os');
                return this.createTokensFallback(text, encoded);
            }

            const tokens = [];
            const isApproximate = !this.isRealTiktoken; // Marcar si son IDs aproximados
            
            // Decodificar cada token individual para obtener el texto exacto
            for (let i = 0; i < encoded.length; i++) {
                const tokenId = encoded[i]; // Este es el ID num√©rico del token
                
                try {
                    // Decodificar solo este token para obtener su texto exacto
                    const tokenText = this.encoder.decode([tokenId]);
                    
                    // Determinar el tipo de token basado en su contenido
                    let type = 'palabra';
                    if (/^\s+$/.test(tokenText)) {
                        type = 'espacio_en_blanco';
                    } else if (/^\d+$/.test(tokenText.trim())) {
                        type = 'number';
                    } else if (/^[.,!?;:'"()\[\]{}]+$/.test(tokenText.trim())) {
                        type = 'punctuation';
                    } else if (tokenText.length === 1 && /[^\w\s]/.test(tokenText)) {
                        type = 'special';
                    } else if (tokenText.startsWith(' ')) {
                        type = 'palabra_con_espacio';
                    } else if (tokenText.length <= 2 && !/^\s+$/.test(tokenText)) {
                        type = 'subword';
                    }

                    tokens.push({
                        text: tokenText,
                        type: type,
                        id: `token_${i}`,
                        tokenId: tokenId, // El ID num√©rico del token
                        index: i,
                        isApproximate: isApproximate // Marcar si es aproximado
                    });
                } catch (decodeError) {
                    console.warn(`Error decodificando token ${tokenId}:`, decodeError);
                    // Si no se puede decodificar, usar el ID como texto
                    tokens.push({
                        text: `[${tokenId}]`,
                        type: 'unknown',
                        id: `token_${i}`,
                        tokenId: tokenId,
                        index: i,
                        isApproximate: true // Siempre aproximado si hay error
                    });
                }
            }

            const typeMessage = isApproximate ? 'IDs APROXIMADOS' : 'IDs REALES';
            console.log(`Tokens creados (${typeMessage}):`, tokens.map(t => `"${t.text}" ‚Üí ${t.tokenId}`));
            return tokens;
        } catch (error) {
            console.error('Error en createTokensFromEncoding:', error);
            return this.createTokensFallback(text, encoded);
        }
    }

    /**
     * M√©todo de respaldo para crear tokens cuando falla la decodificaci√≥n individual
     * @param {string} text - Texto original
     * @param {Array} encoded - Array de tokens codificados
     * @returns {Array} Objetos de token para visualizaci√≥n
     */
    createTokensFallback(text, encoded) {
        // Crear tokens visuales basados en el texto
        const words = text.match(/\S+|\s+/g) || [];
        const tokens = [];
        
        // Distribuir tokens entre palabras proporcionalmente
        const avgTokensPerWord = encoded.length / words.length;
        let tokenIndex = 0;
        
        words.forEach((word, index) => {
            if (/\s/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'espacio en blanco',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else if (/^\d+$/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'number',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else if (/^[.,!?;:'"()\[\]{}]+$/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'punctuation',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else {
                // For longer words, might be split into subwords
                if (word.length > 6 && avgTokensPerWord > 1.3) {
                    const mid = Math.ceil(word.length / 2);
                    tokens.push({
                        text: word.slice(0, mid),
                        type: 'palabra',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                    tokens.push({
                        text: word.slice(mid),
                        type: 'subword',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                } else {
                    tokens.push({
                        text: word,
                        type: 'palabra',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                }
            }
        });

        return tokens;
    }

    /**
     * M√©todo de tokenizaci√≥n de respaldo cuando tiktoken no est√° disponible
     * @param {string} text - Texto a tokenizar
     * @param {string} modelId - Identificador del modelo
     * @returns {{tokens: Array, count: number}}
     */
    fallbackTokenization(text, modelId) {
        const modelInfo = MODELS_DATA[modelId];
        
        console.log('‚ö†Ô∏è Usando tokenizaci√≥n de respaldo - IDs no ser√°n precisos');
        
        // Crear tokens m√°s realistas que simulen el comportamiento de tiktoken
        const tokens = [];
        let tokenIndex = 0;
        
        // Dividir el texto en segmentos (palabras y espacios)
        const segments = text.match(/\S+|\s+/g) || [];
        
        for (const segment of segments) {
            if (/\s/.test(segment)) {
                // Es un espacio en blanco
                tokens.push({
                    text: segment,
                    type: 'espacio_en_blanco',
                    id: `token_${tokenIndex}`,
                    tokenId: this.createDeterministicId(segment, tokenIndex),
                    index: tokenIndex,
                    isApproximate: true
                });
                tokenIndex++;
            } else {
                // Es una palabra - necesitamos dividirla si es muy larga
                const wordTokens = this.splitWordIntoTokens(segment, tokenIndex);
                tokens.push(...wordTokens);
                tokenIndex += wordTokens.length;
            }
        }

        // Calcular conteo de tokens basado en los tokens generados
        const tokenCount = tokens.length;
        
        console.log(`üìä Tokenizaci√≥n de respaldo: "${text}" ‚Üí ${tokenCount} tokens`);
        console.log('üîß Tokens generados:', tokens.map(t => `"${t.text}"`).join(' | '));

        return { tokens, count: tokenCount };
    }

    /**
     * Divide una palabra en tokens m√°s peque√±os (simula comportamiento de tiktoken)
     * @param {string} word - Palabra a dividir
     * @param {number} startIndex - √çndice inicial
     * @returns {Array} Array de tokens
     */
    splitWordIntoTokens(word, startIndex) {
        const tokens = [];
        let currentIndex = startIndex;
        
        // Para palabras muy cortas (‚â§3 caracteres), es un solo token
        if (word.length <= 3) {
            tokens.push({
                text: word,
                type: this.determineTokenType(word),
                id: `token_${currentIndex}`,
                tokenId: this.createDeterministicId(word, currentIndex),
                index: currentIndex,
                isApproximate: true
            });
            return tokens;
        }
        
        // Calcular divisi√≥n m√°s precisa basada en la longitud
        // Para lograr aproximadamente 1 token cada 2.8 caracteres (como tiktoken real)
        const avgCharsPerToken = 2.8;
        const targetTokens = Math.ceil(word.length / avgCharsPerToken);
        const avgChunkSize = word.length / targetTokens;
        
        console.log(`üîç Analizando "${word}" (${word.length} chars) ‚Üí objetivo: ${targetTokens} tokens`);
        
        let position = 0;
        let tokenCount = 0;
        
        while (position < word.length && tokenCount < targetTokens) {
            let chunkSize;
            
            if (tokenCount === targetTokens - 1) {
                // √öltimo token: tomar todo lo que queda
                chunkSize = word.length - position;
            } else {
                // Calcular tama√±o din√°mico basado en lo que queda
                const remaining = word.length - position;
                const tokensLeft = targetTokens - tokenCount;
                chunkSize = Math.round(remaining / tokensLeft);
                
                // Asegurar m√≠nimo 2 caracteres por token (excepto el √∫ltimo)
                chunkSize = Math.max(2, Math.min(chunkSize, 4));
            }
            
            const chunk = word.slice(position, position + chunkSize);
            const tokenType = tokenCount === 0 ? this.determineTokenType(word) : 'subword';
            
            tokens.push({
                text: chunk,
                type: tokenType,
                id: `token_${currentIndex}`,
                tokenId: this.createDeterministicId(chunk, currentIndex),
                index: currentIndex,
                isApproximate: true
            });
            
            console.log(`  Token ${tokenCount + 1}: "${chunk}" (${chunk.length} chars)`);
            
            position += chunkSize;
            currentIndex++;
            tokenCount++;
        }
        
        console.log(`‚úÖ "${word}" dividido en ${tokens.length} tokens:`, tokens.map(t => `"${t.text}"`).join(' | '));
        return tokens;
    }

    /**
     * Determina el tipo de token basado en su contenido
     * @param {string} text - Texto del token
     * @returns {string} Tipo de token
     */
    determineTokenType(text) {
        if (/^\d+$/.test(text)) return 'number';
        if (/^[.,!?;:'"()\[\]{}]+$/.test(text)) return 'punctuation';
        if (/^[^\w\s]+$/.test(text)) return 'special';
        return 'palabra';
    }

    /**
     * Crea un ID determinista para el m√©todo de respaldo
     * @param {string} text - Texto del token
     * @param {number} index - √çndice del token
     * @returns {number} ID determinista
     */
    createDeterministicId(text, index) {
        // Crear un hash simple y determinista del contenido
        let hash = 0;
        for (let i = 0; i < text.length; i++) {
            const char = text.charCodeAt(i);
            hash = ((hash << 5) - hash) + char;
            hash = hash & hash; // Convertir a 32-bit integer
        }
        // Combinar con el √≠ndice para unicidad y mantener en rango razonable
        return Math.abs(hash + index * 1000) % 100000 + 10000;
    }

    /**
     * Obtiene el nombre de visualizaci√≥n para una codificaci√≥n de tokenizador
     * @param {string} encoding - Identificador de codificaci√≥n
     * @returns {string}
     */
    getTokenizerName(encoding) {
        const names = {
            [MODEL_ENCODINGS.O200K_BASE]: 'Tokenizador GPT-4o',
            [MODEL_ENCODINGS.CL100K_BASE]: 'Tokenizador GPT-4',
            [MODEL_ENCODINGS.P50K_BASE]: 'Tokenizador GPT-3',
            [MODEL_ENCODINGS.R50K_BASE]: 'Tokenizador GPT-2'
        };
        return names[encoding] || encoding;
    }

    /**
     * Obtiene la descripci√≥n del algoritmo para un modelo
     * @param {string} modelId - Identificador del modelo
     * @returns {string}
     */
    getAlgorithmName(modelId) {
        if (modelId.includes('gpt-4o')) return 'o200k_base (GPT M√°s Reciente)';
        if (modelId.includes('gpt')) return 'cl100k_base (BPE)';
        if (modelId.includes('claude')) return 'Tokenizaci√≥n Claude (~20% m√°s tokens)';
        if (modelId.includes('llama')) return 'Tokenizaci√≥n Llama (~15% menos tokens)';
        if (modelId.includes('gemini') || modelId.includes('palm')) return 'Google SentencePiece (~10% m√°s)';
        if (modelId.includes('mistral')) return 'Tokenizaci√≥n Mistral (~10% menos)';
        if (modelId.includes('command')) return 'Tokenizaci√≥n Cohere (~5% m√°s)';
        return 'Tokenizaci√≥n Aproximada';
    }
}

// Hacer la clase disponible globalmente
if (typeof window !== 'undefined') {
    window.TokenizationService = TokenizationService;
}
