/**
 * Servicio de Tokenizaci√≥n
 * Maneja toda la l√≥gica de tokenizaci√≥n incluyendo integraci√≥n tiktoken y m√©todos de respaldo
 */

class TokenizationService {
    constructor() {
        this.encoder = null;
        this.isInitialized = false;
        this.initPromise = this.initializeTokenizer();
    }

    /**
     * Inicializa el tokenizador tiktoken
     * @returns {Promise<void>}
     */
    async initializeTokenizer() {
        try {
            console.log('Esperando carga de tiktoken...');
            
            // Esperar hasta que tiktoken est√© disponible (real o respaldo)
            let attempts = 0;
            const maxAttempts = 20; // 10 segundos m√°ximo
            
            while (attempts < maxAttempts) {
                if (typeof window !== 'undefined' && window.tiktokenLoaded) {
                    break;
                }
                await new Promise(resolve => setTimeout(resolve, 500));
                attempts++;
            }
            
            console.log('Verificando disponibilidad de tiktoken...');
            
            // Intentar diferentes formas de acceder a tiktoken
            let tiktokenLib = null;
            
            // Verificar en contexto global
            if (typeof tiktoken !== 'undefined') {
                tiktokenLib = tiktoken;
                console.log('tiktoken encontrado en contexto global');
            }
            // Verificar en window
            else if (typeof window !== 'undefined' && window.tiktoken) {
                tiktokenLib = window.tiktoken;
                console.log('tiktoken encontrado en window');
            }
            
            if (tiktokenLib && typeof tiktokenLib.get_encoding === 'function') {
                try {
                    console.log('Inicializando encoder cl100k_base...');
                    this.encoder = tiktokenLib.get_encoding('cl100k_base');
                    this.isInitialized = true;
                    
                    // Determinar si es tiktoken real o respaldo
                    const isRealTiktoken = !window.tiktokenFallback;
                    console.log(isRealTiktoken ? 'Tiktoken REAL inicializado correctamente' : 'üîß Tiktoken RESPALDO inicializado correctamente');
                    
                    // Hacer una prueba r√°pida
                    const testTokens = this.encoder.encode('Hola mundo');
                    console.log('Prueba de tokenizaci√≥n:', {
                        texto: 'Hola mundo',
                        tokens: testTokens,
                        tipo: isRealTiktoken ? 'IDs REALES' : 'IDs APROXIMADOS'
                    });
                    
                    // Guardar el tipo para referencia
                    this.isRealTiktoken = isRealTiktoken;
                    
                } catch (error) {
                    console.error('Error al inicializar encoder tiktoken:', error);
                    this.isInitialized = false;
                }
            } else {
                console.error('tiktoken no est√° disponible despu√©s de esperar');
                this.isInitialized = false;
            }
        } catch (error) {
            console.error('Error durante la inicializaci√≥n del tokenizador:', error);
            this.isInitialized = false;
        }
    }

    /**
     * Espera a que el tokenizador sea inicializado
     * @returns {Promise<void>}
     */
    async waitForInitialization() {
        await this.initPromise;
    }

    /**
     * Tokeniza texto usando el m√©todo apropiado
     * @param {string} text - Texto a tokenizar
     * @param {string} modelId - Identificador del modelo
     * @returns {Promise<{tokens: Array, count: number}>}
     */
    async tokenizeText(text, modelId) {
        if (!text.trim()) {
            return { tokens: [], count: 0 };
        }

        await this.waitForInitialization();

        const modelInfo = MODELS_DATA[modelId];
        let tokenCount = 0;
        let tokens = [];

        // Intentar usar tiktoken para obtener IDs reales y precisos
        if (this.isInitialized && this.encoder && modelInfo.encoding === MODEL_ENCODINGS.CL100K_BASE) {
            try {
                console.log('Tokenizando con tiktoken para obtener IDs precisos...');
                
                // Codificar el texto para obtener los IDs num√©ricos reales
                const encoded = this.encoder.encode(text);
                tokenCount = encoded.length;
                
                console.log(`Texto: "${text}" ‚Üí ${tokenCount} tokens`);
                console.log('IDs codificados:', encoded);
                
                // Aplicar ratio espec√≠fico del modelo para modelos no-OpenAI
                if (modelInfo.tokenRatio) {
                    tokenCount = Math.round(tokenCount * modelInfo.tokenRatio);
                }

                // Crear objetos de token con IDs reales de tiktoken
                tokens = this.createTokensFromEncoding(text, encoded, modelId);
                
                // Verificar que tenemos los IDs correctos
                const idsVerification = tokens.map(t => t.tokenId);
                console.log('Verificaci√≥n de IDs capturados:', idsVerification);
                
            } catch (error) {
                console.error('Error de tokenizaci√≥n tiktoken:', error);
                return this.fallbackTokenization(text, modelId);
            }
        } else {
            console.log('Usando tokenizaci√≥n de respaldo (tiktoken no disponible)');
            // Tokenizaci√≥n de respaldo para otras codificaciones o cuando tiktoken falla
            return this.fallbackTokenization(text, modelId);
        }

        return {
            tokens: tokens,
            count: tokenCount
        };
    }

    /**
     * Crea tokens visuales desde la codificaci√≥n tiktoken
     * @param {string} text - Texto original
     * @param {Array} encoded - Array de tokens codificados
     * @param {string} modelId - Identificador del modelo
     * @returns {Array} Objetos de token para visualizaci√≥n
     */
    createTokensFromEncoding(text, encoded, modelId) {
        try {
            // Verificar que tenemos el encoder y los datos codificados
            if (!this.encoder || !encoded || encoded.length === 0) {
                console.warn('Encoder no disponible o datos vac√≠os');
                return this.createTokensFallback(text, encoded);
            }

            const tokens = [];
            const isApproximate = !this.isRealTiktoken; // Marcar si son IDs aproximados
            
            // Decodificar cada token individual para obtener el texto exacto
            for (let i = 0; i < encoded.length; i++) {
                const tokenId = encoded[i]; // Este es el ID num√©rico del token
                
                try {
                    // Decodificar solo este token para obtener su texto exacto
                    const tokenText = this.encoder.decode([tokenId]);
                    
                    // Determinar el tipo de token basado en su contenido
                    let type = 'palabra';
                    if (/^\s+$/.test(tokenText)) {
                        type = 'espacio_en_blanco';
                    } else if (/^\d+$/.test(tokenText.trim())) {
                        type = 'number';
                    } else if (/^[.,!?;:'"()\[\]{}]+$/.test(tokenText.trim())) {
                        type = 'punctuation';
                    } else if (tokenText.length === 1 && /[^\w\s]/.test(tokenText)) {
                        type = 'special';
                    } else if (tokenText.startsWith(' ')) {
                        type = 'palabra_con_espacio';
                    } else if (tokenText.length <= 2 && !/^\s+$/.test(tokenText)) {
                        type = 'subword';
                    }

                    tokens.push({
                        text: tokenText,
                        type: type,
                        id: `token_${i}`,
                        tokenId: tokenId, // El ID num√©rico del token
                        index: i,
                        isApproximate: isApproximate // Marcar si es aproximado
                    });
                } catch (decodeError) {
                    console.warn(`Error decodificando token ${tokenId}:`, decodeError);
                    // Si no se puede decodificar, usar el ID como texto
                    tokens.push({
                        text: `[${tokenId}]`,
                        type: 'unknown',
                        id: `token_${i}`,
                        tokenId: tokenId,
                        index: i,
                        isApproximate: true // Siempre aproximado si hay error
                    });
                }
            }

            const typeMessage = isApproximate ? 'IDs APROXIMADOS' : 'IDs REALES';
            console.log(`Tokens creados (${typeMessage}):`, tokens.map(t => `"${t.text}" ‚Üí ${t.tokenId}`));
            return tokens;
        } catch (error) {
            console.error('Error en createTokensFromEncoding:', error);
            return this.createTokensFallback(text, encoded);
        }
    }

    /**
     * M√©todo de respaldo para crear tokens cuando falla la decodificaci√≥n individual
     * @param {string} text - Texto original
     * @param {Array} encoded - Array de tokens codificados
     * @returns {Array} Objetos de token para visualizaci√≥n
     */
    createTokensFallback(text, encoded) {
        // Crear tokens visuales basados en el texto
        const words = text.match(/\S+|\s+/g) || [];
        const tokens = [];
        
        // Distribuir tokens entre palabras proporcionalmente
        const avgTokensPerWord = encoded.length / words.length;
        let tokenIndex = 0;
        
        words.forEach((word, index) => {
            if (/\s/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'espacio en blanco',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else if (/^\d+$/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'number',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else if (/^[.,!?;:'"()\[\]{}]+$/.test(word)) {
                tokens.push({
                    text: word,
                    type: 'punctuation',
                    id: `token_${tokens.length}`,
                    tokenId: encoded[tokenIndex] || 0
                });
                tokenIndex++;
            } else {
                // For longer words, might be split into subwords
                if (word.length > 6 && avgTokensPerWord > 1.3) {
                    const mid = Math.ceil(word.length / 2);
                    tokens.push({
                        text: word.slice(0, mid),
                        type: 'palabra',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                    tokens.push({
                        text: word.slice(mid),
                        type: 'subword',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                } else {
                    tokens.push({
                        text: word,
                        type: 'palabra',
                        id: `token_${tokens.length}`,
                        tokenId: encoded[tokenIndex] || 0
                    });
                    tokenIndex++;
                }
            }
        });

        return tokens;
    }

    /**
     * M√©todo de tokenizaci√≥n de respaldo cuando tiktoken no est√° disponible
     * @param {string} text - Texto a tokenizar
     * @param {string} modelId - Identificador del modelo
     * @returns {{tokens: Array, count: number}}
     */
    fallbackTokenization(text, modelId) {
        const modelInfo = MODELS_DATA[modelId];
        
        console.log('Usando tokenizaci√≥n de respaldo - IDs no ser√°n precisos');
        
        // Tokenizaci√≥n base - aproximadamente 4 caracteres por token para ingl√©s
        let baseTokens = Math.ceil(text.length / 4);
        
        // Ajustar para l√≠mites de palabras - estimaci√≥n m√°s realista
        const words = text.split(/\s+/).filter(w => w.length > 0);
        const avgWordLength = text.length / words.length;
        
        // Aproximaci√≥n m√°s sofisticada
        if (avgWordLength > 6) {
            baseTokens = Math.ceil(baseTokens * 1.1); // Palabras m√°s largas = m√°s tokens de subpalabras
        } else if (avgWordLength < 4) {
            baseTokens = Math.ceil(baseTokens * 0.9); // Palabras m√°s cortas = menos tokens
        }
        
        // Aplicar multiplicadores espec√≠ficos del modelo
        let tokenCount = baseTokens;
        if (modelInfo.tokenRatio) {
            tokenCount = Math.round(tokenCount * modelInfo.tokenRatio);
        }

        // Crear tokens simples para visualizaci√≥n con IDs consistentes (no precisos)
        const segments = text.match(/\S+|\s+/g) || [];
        const tokens = segments.map((segment, index) => {
            // Crear un ID determinista basado en el contenido y posici√≥n
            // Esto no es el ID real de tiktoken, pero ser√° consistente
            const deterministicId = this.createDeterministicId(segment, index);
            
            return {
                text: segment,
                type: /\s/.test(segment) ? 'espacio_en_blanco' : 
                      /^\d+$/.test(segment) ? 'number' :
                      /^[.,!?;:'"()\[\]{}]+$/.test(segment) ? 'punctuation' : 'palabra',
                id: `token_${index}`,
                tokenId: deterministicId, // ID determinista, NO el ID real de tiktoken
                index: index,
                isApproximate: true // Marcar como aproximado
            };
        });

        return { tokens, count: tokenCount };
    }

    /**
     * Crea un ID determinista para el m√©todo de respaldo
     * @param {string} text - Texto del token
     * @param {number} index - √çndice del token
     * @returns {number} ID determinista
     */
    createDeterministicId(text, index) {
        // Crear un hash simple y determinista del contenido
        let hash = 0;
        for (let i = 0; i < text.length; i++) {
            const char = text.charCodeAt(i);
            hash = ((hash << 5) - hash) + char;
            hash = hash & hash; // Convertir a 32-bit integer
        }
        // Combinar con el √≠ndice para unicidad y mantener en rango razonable
        return Math.abs(hash + index * 1000) % 100000 + 10000;
    }

    /**
     * Obtiene el nombre de visualizaci√≥n para una codificaci√≥n de tokenizador
     * @param {string} encoding - Identificador de codificaci√≥n
     * @returns {string}
     */
    getTokenizerName(encoding) {
        const names = {
            [MODEL_ENCODINGS.O200K_BASE]: 'Tokenizador GPT-4o',
            [MODEL_ENCODINGS.CL100K_BASE]: 'Tokenizador GPT-4',
            [MODEL_ENCODINGS.P50K_BASE]: 'Tokenizador GPT-3',
            [MODEL_ENCODINGS.R50K_BASE]: 'Tokenizador GPT-2'
        };
        return names[encoding] || encoding;
    }

    /**
     * Obtiene la descripci√≥n del algoritmo para un modelo
     * @param {string} modelId - Identificador del modelo
     * @returns {string}
     */
    getAlgorithmName(modelId) {
        if (modelId.includes('gpt-4o')) return 'o200k_base (GPT M√°s Reciente)';
        if (modelId.includes('gpt')) return 'cl100k_base (BPE)';
        if (modelId.includes('claude')) return 'Tokenizaci√≥n Claude (~20% m√°s tokens)';
        if (modelId.includes('llama')) return 'Tokenizaci√≥n Llama (~15% menos tokens)';
        if (modelId.includes('gemini') || modelId.includes('palm')) return 'Google SentencePiece (~10% m√°s)';
        if (modelId.includes('mistral')) return 'Tokenizaci√≥n Mistral (~10% menos)';
        if (modelId.includes('command')) return 'Tokenizaci√≥n Cohere (~5% m√°s)';
        return 'Tokenizaci√≥n Aproximada';
    }
}

// Hacer la clase disponible globalmente
if (typeof window !== 'undefined') {
    window.TokenizationService = TokenizationService;
}
